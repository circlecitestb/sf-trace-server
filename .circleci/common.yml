version: 2.1

### Import required orbs
orbs:
  maven: circleci/maven@1.2.0
  orbsdk: snappyflow/orbsdk@1.9.11
  vulnerability-checker: whitesource/vulnerability-checker@19.10.1

### Custom job executor
### TODO: [Pradeep] Change private docker repository to organisation. 
executors:
  circlecienv:
    docker:
      - image: pradeep8055/circlecienv:latest
        auth:
          username: "${DOCKERUSER}"
          password: $DOCKERPASSWORD 
  ubuntumachineimage:
    machine:
      image: ubuntu-2204:2022.04.2          

### Workflow parameters
parameters:
  run-authenticator-job:
    type: boolean
    default: false
  run-sfKafkaInterface-job:
    type: boolean
    default: false
  run-signaturesAndKafkaApis-job:
    type: boolean
    default: false
  run-schemaGenerator-job:
    type: boolean
    default: false
  run-sfKafkaRest-job:
    type: boolean
    default: false
  run-systemMigration-job:
    type: boolean
    default: false 
  run-apmKafkaConnectors-job:
    type: boolean
    default: false     
  run-archivalKafkaConnectors-job:
    type: boolean
    default: false      
  tag-gen-command:
    type: string
    default: |
              function parse_yaml {
                local prefix=$2
                local s='[[:space:]]*' w='[a-zA-Z0-9_]*' fs=$(echo @|tr @ '\034')
                sed -ne "s|^\($s\):|\1|" \
                      -e "s|^\($s\)\($w\)$s:$s[\"']\(.*\)[\"']$s\$|\1$fs\2$fs\3|p" \
                      -e "s|^\($s\)\($w\)$s:$s\(.*\)$s\$|\1$fs\2$fs\3|p"  $1 |
                awk -F$fs '{
                    indent = length($1)/2;
                    vname[indent] = $2;
                    for (i in vname) {if (i > indent) {delete vname[i]}}
                    if (length($3) > 0) {
                      vn=""; for (i=0; i<indent; i++) {vn=(vn)(vname[i])("_")}
                      printf("%s%s%s=\"%s\"\n", "'$prefix'",vn, $2, $3);
                    }
                }'
              }
              ls
              eval $(parse_yaml "version.yaml")
              echo "${AppVersion}"
              GIT_BRANCH=<<pipeline.git.branch>>
              VERSION=$(echo ${AppVersion} | sed 's/\./-/g')
              a=${GIT_BRANCH}-${VERSION}
              TAG=$(echo -n $a | tr -c -s '[:alnum:]' '-')
              echo $TAG
              echo "IMAGETAG=$TAG" >> $BASH_ENV
  helm_url:
    type: string
    default: https://github.com/Circle-CI-ML/helm-charts.git
  helm_branch:
    type: string
    default: master  
       
### Pipeline Jobs
jobs:
  ### wait: This job waits untill all other jobs are completed 
  ### docker tags until other subcomponent workflows are completed.
  wait:
    executor: ubuntumachineimage
    steps:
      - run:
           command: |
             PIPELINE_ID=<< pipeline.id >>
             while :
             do
               curl -XGET https://circleci.com/api/v2/pipeline/$PIPELINE_ID/workflow --header "Circle-Token: $CIRCLE_CI_TOKEN"
               # Fetch Statuses
               STATUSES=$(curl -XGET https://circleci.com/api/v2/pipeline/$PIPELINE_ID/workflow --header "Circle-Token: $CIRCLE_CI_TOKEN" | jq -r ".items[] | .status")

               # Fetch Names
               NAMES=$(curl -XGET https://circleci.com/api/v2/pipeline/$PIPELINE_ID/workflow --header "Circle-Token: $CIRCLE_CI_TOKEN" | jq -r ".items[] | .name")

               declare -a WORKFLOW_STATUSES=($STATUSES)
               declare -a WORKFLOW_NAMES=($NAMES)
               declare -A WORKFLOW_ARR
               DONE=1
               # Constructiing Workflow array
               for key in "${!WORKFLOW_NAMES[@]}"; do
                 WORKFLOW_ARR[${WORKFLOW_NAMES[$key]}]=${WORKFLOW_STATUSES[$key]}
               done
               for NAME in "${!WORKFLOW_ARR[@]}"; do
                 echo "Key: $NAME"
                 echo "Value: ${WORKFLOW_ARR[$NAME]}"
                 if [[ ${WORKFLOW_ARR[$NAME]} == failed ]]; then
                   exit 1
                 fi
                 if [[ ${WORKFLOW_ARR[$NAME]} == running ]] && [[ $NAME != release ]]; then
                   DONE=0
                 fi
               done
               echo $DONE
               if [[ $DONE != 0 ]]; then
                 echo "Breaking loop"
                 break
               fi
               sleep 30
             done
  
  ### updateBaseRevision: This job updates the BASE_REVISION env in context
  updateBaseRevision:
    executor: ubuntumachineimage
    steps:
      - run:
           command: |
             BRANCH=<<pipeline.git.branch>>
             GIT_BRANCH=$(echo -n $BRANCH | tr -c -s '[:alnum:]' '_')
             curl -XPOST https://circleci.com/api/v2/project/gh/$CIRCLE_PROJECT_USERNAME/$CIRCLE_PROJECT_REPONAME/envvar --header "Content-Type: application/json" --header "Circle-Token: $CIRCLE_CI_TOKEN" --data '{"name":"'"${GIT_BRANCH}"'", "value": "'"${CIRCLE_SHA1}"'"}'

  ### generateTar: This job generates tar file of helm charts.
  generateTar:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run: 
          command: << pipeline.parameters.tag-gen-command >>
      - run: 
          command: |
             echo << pipeline.parameters.helm_url >>
             echo << pipeline.parameters.helm_branch >>
      - orbsdk/generate_helm_tar:
          directory: "helm-charts/charts/sf-datapath"
          imageversion: "${IMAGETAG}"
          helmurl: << pipeline.parameters.helm_url >>
          helmbranch: << pipeline.parameters.helm_branch >>
          dockerregistry: pradeep8055
          chartsdir: /home/circleci/project/helm-charts/charts
          component: sf-datapath
      - store_artifacts:
          path: /home/circleci/project/helm-charts/charts/sf-datapath.tar.gz

  ### releaseDockerTag: This job updates the docker image tags for all the sub component 
  ### basically pulls latest, retag it and push again.
  reTagSubcomponents:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run: 
          command: << pipeline.parameters.tag-gen-command >>
      - orbsdk/retag_subcomponents:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          dockerrepository: "${DOCKERUSER}"
          cluster: non-production
          imagetag: "${IMAGETAG}"
          snappyflowversion: "${SFTAG}"
          gitbranch: <<pipeline.git.branch>>
          components: 'authenticator arch-kafka-connect sf-kafka-rest schema-generator apm-kafka-connect sfk-interface signatures'      
  
  ### authenticatorCodeCheck: This job does static code check, 
  ### lint and stores the result in artifact
  authenticatorCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: authenticator
      - store_artifacts:
          path: authenticator/authenticator.txt
  
  ### authenticatorBuild: This job builds docker image from branches other than master and release branch

  authenticatorBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: authenticator
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: authenticator
          gitbranch: <<pipeline.git.branch>>
  
  ### sfKafkaInterfaceCodeCheck: This job does static code check, 
  ### lint and stores the result in artifact
  sfKafkaInterfaceCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: sf-kafka-interface
      - store_artifacts:
          path: sf-kafka-interface/sf-kafka-interface.txt
  
  ### sfKafkaInterfaceBuild: This job builds docker image from branches other than master and release branch

  sfKafkaInterfaceBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: sfk-interface
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: sf-kafka-interface
          gitbranch: <<pipeline.git.branch>>
  
  ### signaturesAndKafkaApisCodeCheck: This job does static code check, 
  ### lint and stores the result in artifact
  signaturesAndKafkaApisCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: signatures-and-kafka-apis
      - store_artifacts:
          path: signatures-and-kafka-apis/signatures-and-kafka-apis.txt
  
  ### signaturesAndKafkaApisBuild: This job builds docker image from branches other than master and release branch

  signaturesAndKafkaApisBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: signatures
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: signatures-and-kafka-apis
          gitbranch: <<pipeline.git.branch>>
  
  ### schemaGeneratorCodeCheck: This job does static code check, 
  ### lint and stores the result in artifact
  schemaGeneratorCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: schema-generator
      - store_artifacts:
          path: schema-generator/schema-generator.txt
  
  ### schemaGeneratorBuild: This job builds docker image from branches other than master and release branch

  schemaGeneratorBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: schema-generator
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: schema-generator
          gitbranch: <<pipeline.git.branch>>
  
  ### sfKafkaRestCodeCheck:This job does static code check, 
  ### lint and stores the result in artifact
  sfKafkaRestCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: sf-kafka-rest
      - store_artifacts:
          path: sf-kafka-rest/sf-kafka-rest.txt
  
  ### sfKafkaRestBuild: This job builds docker image from branches other than master and release branch

  sfKafkaRestBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: sf-kafka-rest
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: sf-kafka-rest
          gitbranch: <<pipeline.git.branch>>
  
  ### systemMigrationCodeCheck: This job does static code check, 
  ### lint and stores the result in artifact
  systemMigrationCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: system-migration
      - store_artifacts:
          path: system-migration/system-migration.txt
  
  ### systemMigrationBuild: This job builds docker image from branches other than master and release branch

  systemMigrationBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: archival-system-migration
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: system-migration
          gitbranch: <<pipeline.git.branch>>
  
  ### apmKafkaConnectorsCodeCheck: This job does static code check, 
  ### lint and stores the result in artifact
  apmKafkaConnectorsCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: connectors
      - store_artifacts:
          path: connectors/apm-kafka-connectors.txt
  
  ### apmKafkaConnectorsBuild: This job builds docker image from branches other than master and release branch

  apmKafkaConnectorsBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - run:
          command: cp connectors/APM-Dockerfile connectors/Dockerfile          
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: apm-kafka-connect
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: connectors
          gitbranch: <<pipeline.git.branch>>
  
  ### archivalKafkaConnectorsCodeCheck: This job does static code check, 
  ### lint and stores the result in artifact
  archivalKafkaConnectorsCodeCheck:
    executor: circlecienv
    steps:
      - checkout
      - orbsdk/static_code_check:
          directory: connectors
      - store_artifacts:
          path: connectors/archival-kafka-connectors.txt
  
  ### archivalKafkaConnectorsBuild: This job builds docker image from branches other than master and release branch

  archivalKafkaConnectorsBuild:
    executor: ubuntumachineimage
    steps:
      - checkout
      - run:
          command: << pipeline.parameters.tag-gen-command >>
      - run:
          command: cp connectors/Archival-Dockerfile connectors/Dockerfile           
      - orbsdk/build_docker:
          dockeruser: "${DOCKERUSER}"
          dockerpassword: "${DOCKERPASSWORD}"
          imagename: arch-kafka-connect
          imagetag: "${IMAGETAG}"
          dockerrepository: "${DOCKERUSER}"
          appdirectory: connectors
          gitbranch: <<pipeline.git.branch>>

### Pipeline Workflows
workflows:
  ### authenticator: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  authenticator:
    when:
      equal: [true, << pipeline.parameters.run-authenticator-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./authenticator
      - authenticatorCodeCheck:
          name: Static_Code_Check
          context: Build_Env_Vars
          requires:
            - Check_Opensource_Vulnerabilities
      - authenticatorBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            - Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### sfKafkaInterface: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  sfKafkaInterface:
    when:
      equal: [true, << pipeline.parameters.run-sfKafkaInterface-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./sf-kafka-interface
      - sfKafkaInterfaceCodeCheck:
          name: Static_Code_Check
          context: Build_Env_Vars
          requires:
            - Check_Opensource_Vulnerabilities
      - sfKafkaInterfaceBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            - Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### signaturesAndKafkaApis: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  signaturesAndKafkaApis:
    when:
      equal: [true, << pipeline.parameters.run-signaturesAndKafkaApis-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./signatures-and-kafka-apis
      #- signaturesAndKafkaApisCodeCheck:
      #    name: Static_Code_Check
      #    context: Build_Env_Vars
      #    requires:
      #      - Check_Opensource_Vulnerabilities
      - signaturesAndKafkaApisBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            #- Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### schemaGenerator: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  schemaGenerator:
    when:
      equal: [true, << pipeline.parameters.run-schemaGenerator-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./schema-generator
      - schemaGeneratorCodeCheck:
          name: Static_Code_Check
          context: Build_Env_Vars
          requires:
            - Check_Opensource_Vulnerabilities
      - schemaGeneratorBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            - Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### sfKafkaRest: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  sfKafkaRest:
    when:
      equal: [true, << pipeline.parameters.run-sfKafkaRest-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./sf-kafka-rest
      #- sfKafkaRestCodeCheck:
      #    name: Static_Code_Check
      #    context: Build_Env_Vars
      #    requires:
      #      - Check_Opensource_Vulnerabilities
      - sfKafkaRestBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            #- Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### systemMigration: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  systemMigration:
    when:
      equal: [true, << pipeline.parameters.run-systemMigration-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./system-migration
      - systemMigrationCodeCheck:
          name: Static_Code_Check
          context: Build_Env_Vars
          requires:
            - Check_Opensource_Vulnerabilities
      - systemMigrationBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            - Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### apmKafkaConnectors: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  apmKafkaConnectors:
    when:
      equal: [true, << pipeline.parameters.run-apmKafkaConnectors-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./connectors
      #- apmKafkaConnectorsCodeCheck:
      #    name: Static_Code_Check
      #    context: Build_Env_Vars
      #    requires:
      #      - Check_Opensource_Vulnerabilities
      - apmKafkaConnectorsBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            #- Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### archivalKafkaConnectors: This workflow does following:
  ### 1. Opensource Vulnerability check.
  ### 2. Static_Code_Check.
  ### 3. Build Docker
  archivalKafkaConnectors:
    when:
      equal: [true, << pipeline.parameters.run-archivalKafkaConnectors-job >>]
    jobs:
      - vulnerability-checker/scan:
          name: Check_Opensource_Vulnerabilities
          context: Build_Env_Vars
          directory: ./connectors
      #- archivalKafkaConnectorsCodeCheck:
      #    name: Static_Code_Check
      #    context: Build_Env_Vars
      #    requires:
      #      - Check_Opensource_Vulnerabilities
      - archivalKafkaConnectorsBuild:
          name: Build_Docker
          context: Build_Env_Vars
          requires:
            #- Static_Code_Check
            - Check_Opensource_Vulnerabilities
  
  ### release:  This workflow does following:
  ### 1. Wait for other workflows to complete
  ### 2. Retag Subcomponents, bump version
  ### 3. generates helm tar
  ### 4. updates base revision
  release:
    jobs:
      - wait:
          context: Build_Env_Vars
      - reTagSubcomponents:
          context: Build_Env_Vars
          requires:
            - wait
      - generateTar:
          context: Build_Env_Vars
          requires:
            - reTagSubcomponents
      - updateBaseRevision:
          context: Build_Env_Vars
          requires:
            - generateTar        